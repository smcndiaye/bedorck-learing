{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>Copyright 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved.<br>\n",
    "This is AWS Content subject to the terms of the Customer Agreement</small>\n",
    "\n",
    "# Module 1.2: Video Generation Pipeline Walkthrough\n",
    "\n",
    "This notebook demonstrates the key steps in ROBO-Reviewer video generation pipeline. This pipeline automates the entire process from concept to video, leveraging Nova Reel 1.1 to transform your rough ideas into polished video content.\n",
    "\n",
    "## A. Overview\n",
    "\n",
    "The video generation pipeline consists of four main steps:\n",
    "1. **Generate Prompts** - Create optimized prompts using Claude\n",
    "2. **Start Video Generation** - Initiate async video generation jobs\n",
    "3. **Monitor Status** - Check job progress and completion\n",
    "4. **Complete Pipeline** - End-to-end video generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Install Dependencies\n",
    "\n",
    "First, let's install the required packages for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q matplotlib opencv-python Pillow tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pprint\n",
    "from utility import create_bedrock_execution_role, create_oss_policy_attach_bedrock_execution_role, create_policies_in_oss, interactive_sleep\n",
    "import random\n",
    "from retrying import retry "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Configuration\n",
    "\n",
    "Before we start generating videos, let's configure our parameters. Each setting controls a specific aspect of the video generation process:\n",
    "\n",
    "- S3 bucket will be automatically detected from CloudFormation or fallback to config.json\n",
    "- <font color='red'>Feel free to change the `USER_REQUEST` in the cell below</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = random.randrange(200, 900)\n",
    "sts_client = boto3.client('sts')\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "bedrock_runtime = boto3_session.client('bedrock-runtime', region_name=region_name)\n",
    "service = 'aoss'\n",
    "s3_client = boto3.client('s3')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "s3_suffix = f\"{region_name}-{account_id}\"\n",
    "S3_BUCKET = f'bedrock-kb-{s3_suffix}' # replace it with your bucket name.\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket bedrock-kb-us-east-1-442579209021 Exists\n"
     ]
    }
   ],
   "source": [
    "# Check if bucket exists, and if not create S3 bucket for knowledge base data source\n",
    "try:\n",
    "    s3_client.head_bucket(Bucket=bucket_name)\n",
    "    print(f'Bucket {bucket_name} Exists')\n",
    "except ClientError as e:\n",
    "    print(f'Creating bucket {bucket_name}')\n",
    "    if region_name == \"us-east-1\":\n",
    "        S3_BUCKET = s3_client.create_bucket(\n",
    "            Bucket=bucket_name)\n",
    "    else:\n",
    "        S3_BUCKET = s3_client.create_bucket(\n",
    "        Bucket=bucket_name,\n",
    "        CreateBucketConfiguration={ 'LocationConstraint': region_name }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bedrock-kb-us-east-1-442579209021'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Configuration\n",
    "#session = boto3.Session()\n",
    "#bedrock_runtime = session.client('bedrock-runtime')\n",
    "\n",
    "# Import S3 bucket configuration utility\n",
    "#from utils.config import get_s3_bucket\n",
    "\n",
    "# Get S3 bucket name\n",
    "#S3_BUCKET = '' #get_s3_bucket(session)\n",
    "\n",
    "# Video generation parameters\n",
    "\n",
    "# Your creative concept\n",
    "USER_REQUEST = \"A cat playing with a ball of yarn in a cozy living room\"\n",
    "\n",
    "# Video length: must be 6 or multiples of 6 (6, 12, 18... up to 120)\n",
    "DURATION_SECONDS = 6  \n",
    "DURATION_SECONDS_LONG = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S3_BUCKET = \"demo-real-nova\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Step 1 - Generate Optimized Prompts\n",
    "\n",
    "The first step transforms your rough idea into professional video prompts. The `generate_prompts` function acts as an intelligent prompt engineer, using Nova Premier to:\n",
    "\n",
    "**Key Operations:**\n",
    "1. **Analyze video duration** - Determines if we need short (‚â§6s) or long video prompts\n",
    "2. **Apply camera motion vocabulary** - Selects from 17 professional camera movements\n",
    "3. **Structure prompts** - Creates descriptive captions with technical specifications\n",
    "4. **Retry logic** - Handles API failures with exponential backoff\n",
    "5. **Parse results** - Extracts valid JSON arrays from LLM's response\n",
    "\n",
    "**Why this matters:** Raw user requests like 'cat playing' become cinematic prompts with proper lighting, camera work, and technical specs that Nova Reel can execute effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts(\n",
    "    bedrock_runtime,\n",
    "    user_request,\n",
    "    num_prompts = 1,\n",
    "    video_duration = 6,\n",
    "    model_id=\"us.amazon.nova-premier-v1:0\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Generate n video prompts for Amazon Nova Reel based on a given scenario.\n",
    "    \n",
    "    Args:\n",
    "        bedrock_runtime: AWS Bedrock runtime client\n",
    "        user_request (str): The video generation request from the user about what types of video to be generated.\n",
    "        num_prompts: the number of prompts to be generated.\n",
    "        video_duration: the video duration in seconds\n",
    "        model_id (str): model ID for prompt generation\n",
    "        \n",
    "    Returns:\n",
    "        list: List of generated video prompts\n",
    "    \"\"\"\n",
    "    long_video_flag = False\n",
    "    num_scenes = 1\n",
    "    if video_duration > 6:\n",
    "        long_video_flag = True\n",
    "        num_scenes = video_duration // 6\n",
    "    print(f\"num_scenes: {num_scenes}\")\n",
    "    print(f\"long video?: {long_video_flag}\")\n",
    "    \n",
    "    # Camera motion dictionary\n",
    "    camera_motions = {\n",
    "        'aerial shot': ['Aerial shot', 'Drone shot', 'FPV drone shot', 'First person view drone shot'],\n",
    "        'arc shot': ['Arc shot', '360 degree shot', '360 tracking shot', 'Orbit shot'],\n",
    "        'clockwise rotation': ['Clockwise rotating shot', 'Camera rotates clockwise', 'Camera rolls clockwise'],\n",
    "        'counterclockwise rotation': ['Counterclockwise rotating shot', 'Camera rotates counterclockwise', 'Camera rolls counterclockwise'],\n",
    "        'dolly in': ['Dolly in shot', 'Dolly in', 'Camera moves forward', 'Camera moving forward'],\n",
    "        'dolly out': ['Dolly out shot', 'Dolly out', 'Camera moves backward', 'Camera moving backward'],\n",
    "        'pan left': ['Pan left shot', 'Pan left', 'Camera pans left', 'Camera moves left'],\n",
    "        'pan right': ['Pan right shot', 'Pan right', 'Camera pans right', 'Camera moves right'],\n",
    "        'whip pan': ['Whip pan left', 'Whip pan right'],\n",
    "        'pedestal down': ['Pedestal down shot', 'Pedestal down', 'Camera moves down', 'Camera moving down'],\n",
    "        'pedestal up': ['Pedestal up shot', 'Pedestal up', 'Camera moves up', 'Camera moving up'],\n",
    "        'static shot': ['Static shot', 'Fixed shot'],\n",
    "        'tilt down': ['Tilt down shot', 'Tilt down', 'Camera tilts down', 'Camera moving down'],\n",
    "        'tilt up': ['Tilt up shot', 'Tilt up', 'Camera tilts up', 'Camera moving up'],\n",
    "        'whip tilt': ['Whip tilt up', 'Whip tilt down'],\n",
    "        'track left': ['Track left', 'Truck left', 'Camera tracks left', 'Camera moving to the left'],\n",
    "        'track right': ['Track right', 'Truck right', 'Camera tracks right', 'Camera moving to the right'],\n",
    "        'zoom in': ['Zoom in', 'Camera zooms in', 'Camera moves forward'],\n",
    "        'zoom out': ['Zoom out', 'Camera zooms out', 'Camera moves backward'],\n",
    "        'whip zoom': ['Whip zoom in', 'Whip zoom out'],\n",
    "        'dolly zoom': ['Dolly zoom', 'Dolly zoom shot', 'Dolly zoom effect'],\n",
    "        'following shot': ['Following shot']\n",
    "    }\n",
    "    \n",
    "    # Refined prompt template for Claude\n",
    "    prompt_template_short = f\"\"\"Generate {num_prompts} different prompts for the Amazon Nova Reel video generation model based on the given request. Nova Reel generates video clips from text descriptions.\n",
    "\n",
    "<scenario>\n",
    "{user_request}\n",
    "</scenario>\n",
    "\n",
    "<guidelines>\n",
    "Video generation prompts should be descriptive captions, not commands. Include details about subject, action, environment, lighting, style, and camera motion.\n",
    "\n",
    "Requirements:\n",
    "- Prompts must be no longer than 512 characters.\n",
    "- Place camera movement descriptions at start or end of prompt\n",
    "- Avoid negation words (no, not, without)\n",
    "- Write as scene descriptions, not instructions\n",
    "\n",
    "Camera motions available: {json.dumps(camera_motions, indent=2)}\n",
    "</guidelines>\n",
    "\n",
    "<examples>\n",
    "Cinematic dolly shot of a juicy cheeseburger with melting cheese, fries, and a condensation-covered cola on a worn diner table. Natural lighting, visible steam and droplets. 4k, photorealistic, shallow depth of field.\n",
    "\n",
    "Arc shot on a salad with dressing, olives and other vegetables; 4k; Cinematic.\n",
    "\n",
    "First person view of a motorcycle riding through the forest road.\n",
    "\n",
    "Closeup of a large seashell in the sand. Gentle waves flow around the shell. Camera zoom in.\n",
    "\n",
    "Clothes hanging on a thread to dry, windy; sunny day; 4k; Cinematic; highest quality;\n",
    "\n",
    "Slow cam of a man middle age; 4k; Cinematic; in a sunny day; peaceful; highest quality; dolly in;\n",
    "\n",
    "A mushroom drinking a cup of coffee while sitting on a couch, photorealistic.\n",
    "</examples>\n",
    "\n",
    "Generate {num_prompts} unique prompts for the scenario. Each prompt should:\n",
    "1. Be clear and concise (under 512 characters)\n",
    "2. Include appropriate camera motion at beginning or end\n",
    "3. Describe the scene naturally (avoid starting with verbs)\n",
    "4. Provide sufficient context for video generation\n",
    "\n",
    "Return only a Python list of the {num_prompts} prompts, no additional text.\n",
    "\"\"\"\n",
    "\n",
    "    prompt_template_long = f\"\"\"Generate {num_prompts} different prompts for the Amazon Nova Reel video generation model based on the given request. Nova Reel generates video clips from text descriptions.\n",
    "\n",
    "<scenario>\n",
    "{user_request}\n",
    "</scenario>\n",
    "\n",
    "<guidelines>\n",
    "Video generation prompts should be descriptive captions, not commands. Include details about subject, action, environment, lighting, style, and camera motion.\n",
    "\n",
    "Requirements:\n",
    "- Each prompt must be no longer than 4000 characters.\n",
    "- Each prompt must contain {num_scenes + 1} sentences.\n",
    "- Each sentence except the last one in the prompt represented a scene in the generated video. The last sentence contains the technical specifications, such as 4k, photorealistic, Cinematic.\n",
    "- Place camera movement descriptions at start or end of the sentence. But this is optional.\n",
    "- Avoid negation words (no, not, without)\n",
    "- Write as scene descriptions, not instructions\n",
    "\n",
    "Camera motions available: {json.dumps(camera_motions, indent=2)}\n",
    "</guidelines>\n",
    "\n",
    "<examples>\n",
    "Norwegian fjord with still water reflecting mountains in perfect symmetry. Uninhabited wilderness of Giant sequoia forest with sunlight filtering between massive trunks. Sahara desert sand dunes with perfect ripple patterns. Alpine lake with crystal clear water and mountain reflection. Ancient redwood tree with detailed bark texture. Arctic ice cave with blue ice walls and ceiling. Bioluminescent plankton on beach shore at night. Bolivian salt flats with perfect sky reflection. Bamboo forest with tall stalks in filtered light. Cherry blossom grove against blue sky. Lavender field with purple rows to horizon. Autumn forest with red and gold leaves. Tropical coral reef with fish and colorful coral. Antelope Canyon with light beams through narrow passages. Banff lake with turquoise water and mountain backdrop. Joshua Tree desert at sunset with silhouetted trees. Iceland moss- covered lava field. Amazon lily pads with perfect symmetry. Hawaiian volcanic landscape with lava rock. New Zealand glowworm cave with blue ceiling lights. 8K nature photography, professional landscape lighting, no movement transitions, perfect exposure for each environment, natural color grading.\n",
    "\n",
    "Explosion of colored powder against black background. Start with slow-motion closeup of single purple powder burst. Dolly out revealing multiple powder clouds in vibrant hues colliding mid-air. Track across spectrum of colors mixing: magenta, yellow, cyan, orange. Zoom in on particles illuminated by sunbeams. Arc shot capturing complete color field. 4K, festival celebration, high-contrast lighting\n",
    "</examples>\n",
    "\n",
    "Generate {num_prompts} unique prompts for the scenario. Each prompt should:\n",
    "1. Be clear and concise (under 4000 characters)\n",
    "2. Include appropriate camera motion at beginning or end\n",
    "3. Describe the scene naturally (avoid starting with verbs)\n",
    "4. Provide sufficient context for video generation\n",
    "\n",
    "Return only a Python list of the {num_prompts} prompts, no additional text.\n",
    "\"\"\"\n",
    "\n",
    "    if long_video_flag:\n",
    "        input_prompt = prompt_template_long\n",
    "    else:\n",
    "        input_prompt = prompt_template_short\n",
    "\n",
    "\n",
    "    retry_delays = [1, 2, 4, 8, 16]\n",
    "    messages = [\n",
    "    {\"role\": \"user\",\n",
    "        \"content\": [{\"text\": input_prompt}]}\n",
    "    ]\n",
    "    for attempt, delay in enumerate(retry_delays + [None]):\n",
    "        print(f\"inovke LLM - attempt {attempt}\")\n",
    "        try:\n",
    "            response = bedrock_runtime.converse(\n",
    "                modelId=model_id,\n",
    "                messages=messages,\n",
    "                inferenceConfig={\"temperature\": 0},\n",
    "            )\n",
    "            generated_text = response['output']['message']['content'][0][\"text\"]\n",
    "            break\n",
    "        except (ClientError, Exception) as e:\n",
    "            print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "            if delay is not None:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Extract the Python list from the response\n",
    "    try:\n",
    "        # Find the list in the response text\n",
    "        start_idx = generated_text.find('[')\n",
    "        end_idx = generated_text.rfind(']') + 1\n",
    "        list_str = generated_text[start_idx:end_idx]\n",
    "        return_prompts = json.loads(list_str)  # Validate JSON\n",
    "        return return_prompts[0:num_prompts]\n",
    "    # raise error if failed to generate prompts\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error parsing generated text: {e}\" + \"Failed to generate prompts. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating video prompts for short video...\n",
      "num_scenes: 1\n",
      "long video?: False\n",
      "inovke LLM - attempt 0\n",
      "\n",
      "Generated 1 prompts:\n",
      "1. Softly lit living room with plush furniture. A curious cat bats at a colorful yarn ball, unraveling it playfully. Sunlight streams through sheer curtains. Camera pans right, capturing the feline's joyful antics.\n",
      "\n",
      "Generating video prompts for long video...\n",
      "num_scenes: 5\n",
      "long video?: True\n",
      "inovke LLM - attempt 0\n",
      "\n",
      "Generated 1 prompts:\n",
      "1. Soft morning light streams through sheer curtains in a cozy living room. A fluffy grey cat sits on a plush rug, batting playfully at a tangled ball of yarn. Camera pans right to show the cat chasing the rolling yarn across wooden floors. The feline pounces with precision, wrapping itself in the yarn. Camera zooms in to capture whiskers twitching in delight. Rendered in 4K with warm, photorealistic lighting and smooth cinematic motion.\n"
     ]
    }
   ],
   "source": [
    "# Generate prompts using Claude\n",
    "print(\"Generating video prompts for short video...\")\n",
    "prompts_short = generate_prompts(\n",
    "    bedrock_runtime=bedrock_runtime,\n",
    "    user_request=USER_REQUEST,\n",
    "    num_prompts=1,\n",
    "    video_duration=DURATION_SECONDS,\n",
    "    model_id=\"us.amazon.nova-premier-v1:0\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(prompts_short)} prompts:\")\n",
    "for i, prompt in enumerate(prompts_short, 1):\n",
    "    print(f\"{i}. {prompt}\")\n",
    "\n",
    "\n",
    "print(\"\\nGenerating video prompts for long video...\")\n",
    "prompts_long = generate_prompts(\n",
    "    bedrock_runtime=bedrock_runtime,\n",
    "    user_request=USER_REQUEST,\n",
    "    num_prompts=1,\n",
    "    video_duration=DURATION_SECONDS_LONG,\n",
    "    model_id=\"us.amazon.nova-premier-v1:0\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(prompts_long)} prompts:\")\n",
    "for i, prompt in enumerate(prompts_long, 1):\n",
    "    print(f\"{i}. {prompt}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Step 2 - Start Video Generation Jobs\n",
    "\n",
    "Now we take our optimized prompts and submit them to Nova Reel for video generation. The `start_invocation_t2v` function handles the complexity of AWS Bedrock's async API:\n",
    "\n",
    "**Key Operations:**\n",
    "1. **Task type selection** - Uses `TEXT_VIDEO` for short videos (‚â§6s) or `MULTI_SHOT_AUTOMATED` for longer videos\n",
    "2. **Configuration setup** - Applies video parameters (resolution, FPS, duration)\n",
    "3. **Seed management** - Increments seeds for each prompt to ensure variety\n",
    "4. **Async invocation** - Starts non-blocking video generation jobs\n",
    "5. **ARN collection** - Returns job identifiers for status tracking\n",
    "\n",
    "**Why async matters:** Video generation takes 3-5 minutes per video. Async processing lets us start multiple jobs simultaneously and do other work while they render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_invocation_t2v(\n",
    "    bedrock_runtime,\n",
    "    s3_bucket:str,\n",
    "    text_prompts:list,\n",
    "    duration_seconds:int = 6,\n",
    "    fps:int = 24,\n",
    "    dimension:str = \"1280x720\",\n",
    "    seed:int = 42,\n",
    "    model_id:str = \"amazon.nova-reel-v1:1\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Start invocations to generate videos from text prompts.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    bedrock_runtime: boto3.client\n",
    "        The Bedrock Runtime client.\n",
    "\n",
    "    s3_bucket: str\n",
    "        The S3 bucket where the video will be stored.\n",
    "\n",
    "    text_prompt: list\n",
    "        The text prompt(s) to generate video(s).\n",
    "\n",
    "    duration_seconds: int\n",
    "        The duration of the video in seconds. Default is 6.\n",
    "\n",
    "    fps: int\n",
    "        The frames per second of the video. Default is 24.\n",
    "\n",
    "    dimension: str\n",
    "        The dimension of the video. Default is \"1280x720\".\n",
    "\n",
    "    seed: int\n",
    "        The seed to use for the video generation. Default is 0.\n",
    "\n",
    "    model_id: str\n",
    "        The model ID to use for the video generation. Default is \n",
    "        \"amazon.nova-reel-v1:1\".\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str or list\n",
    "        The invocation ARN(s).\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle both single prompt and list of prompts\n",
    "    prompts = text_prompts\n",
    "    \n",
    "    invocation_arns = []\n",
    "\n",
    "    if duration_seconds <= 6:\n",
    "        \n",
    "        for i, prompt in enumerate(prompts):\n",
    "            skip_flag = False\n",
    "            model_input = {\n",
    "                \"taskType\": \"TEXT_VIDEO\",\n",
    "                \"textToVideoParams\": {\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                \"videoGenerationConfig\": {\n",
    "                    \"durationSeconds\": duration_seconds,\n",
    "                    \"fps\": fps,\n",
    "                    \"dimension\": dimension,\n",
    "                    \"seed\": seed + i,  # Increment seed for each prompt\n",
    "                },\n",
    "            }\n",
    "\n",
    "            retry_delays = [32, 32, 32, 32, 32]\n",
    "            for attempt, delay in enumerate(retry_delays + [None]):\n",
    "                print(f\"inovke Nova Reel - attempt {attempt}\")\n",
    "                try:\n",
    "                    invocation = bedrock_runtime.start_async_invoke(\n",
    "                        modelId = model_id,\n",
    "                        modelInput=model_input,\n",
    "                        outputDataConfig={\n",
    "                            \"s3OutputDataConfig\": {\n",
    "                                \"s3Uri\": \"s3://\" + s3_bucket\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "                    break\n",
    "                except (ClientError, Exception) as e:\n",
    "                    print(f\"ERROR: Reason: {e}\")\n",
    "                    if delay is not None:\n",
    "                        print(f\"Retryinng in {delay} seconds.\")\n",
    "                        time.sleep(delay)\n",
    "                    else:\n",
    "                        skip_flag = True\n",
    "\n",
    "            if not skip_flag:\n",
    "                invocation_arns.append(invocation[\"invocationArn\"])\n",
    "    else:\n",
    "\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            skip_flag = False\n",
    "            model_input = {\n",
    "                \"taskType\": \"MULTI_SHOT_AUTOMATED\",\n",
    "                \"multiShotAutomatedParams\": {\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                \"videoGenerationConfig\": {\n",
    "                    \"durationSeconds\": duration_seconds,\n",
    "                    \"fps\": fps,\n",
    "                    \"dimension\": dimension,\n",
    "                    \"seed\": seed + i,  # Increment seed for each prompt\n",
    "                },\n",
    "            }\n",
    "\n",
    "            retry_delays = [32, 32, 32, 32, 32]\n",
    "            for attempt, delay in enumerate(retry_delays + [None]):\n",
    "                print(f\"inovke Nova Reel - attempt {attempt}\")\n",
    "                try:\n",
    "                    invocation = bedrock_runtime.start_async_invoke(\n",
    "                        modelId = model_id,\n",
    "                        modelInput=model_input,\n",
    "                        outputDataConfig={\n",
    "                            \"s3OutputDataConfig\": {\n",
    "                                \"s3Uri\": \"s3://\" + s3_bucket\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "                    break\n",
    "                except (ClientError, Exception) as e:\n",
    "                    print(f\"ERROR: Reason: {e}\")\n",
    "                    if delay is not None:\n",
    "                        print(f\"Retryinng in {delay} seconds.\")\n",
    "                        time.sleep(delay)\n",
    "                    else:\n",
    "                        skip_flag = True\n",
    "\n",
    "            if not skip_flag:\n",
    "                invocation_arns.append(invocation[\"invocationArn\"])\n",
    "    \n",
    "    return invocation_arns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video generation jobs...\n",
      "inovke Nova Reel - attempt 0\n",
      "\n",
      "Started 1 video generation jobs:\n",
      "1. arn:aws:bedrock:us-east-1:442579209021:async-invoke/7zwg4d79lkwc\n",
      "inovke Nova Reel - attempt 0\n",
      "\n",
      "Started 1 video generation jobs:\n",
      "1. arn:aws:bedrock:us-east-1:442579209021:async-invoke/2uaqgzv2q879\n",
      "\n",
      "üöÄ Jobs are now running asynchronously on Nova Reel infrastructure.\n",
      "   Each ARN is a unique identifier we'll use to track progress.\n",
      "   Videos will be saved to your S3 bucket when complete.\n"
     ]
    }
   ],
   "source": [
    "# Start video generation jobs\n",
    "print(\"Starting video generation jobs...\")\n",
    "invocation_arns = start_invocation_t2v(\n",
    "    bedrock_runtime=bedrock_runtime,\n",
    "    s3_bucket=S3_BUCKET,\n",
    "    text_prompts=prompts_short,\n",
    "    duration_seconds=DURATION_SECONDS\n",
    ")\n",
    "\n",
    "print(f\"\\nStarted {len(invocation_arns)} video generation jobs:\")\n",
    "for i, arn in enumerate(invocation_arns, 1):\n",
    "    print(f\"{i}. {arn}\")\n",
    "\n",
    "invocation_arns_2 = start_invocation_t2v(\n",
    "    bedrock_runtime=bedrock_runtime,\n",
    "    s3_bucket=S3_BUCKET,\n",
    "    text_prompts=prompts_long,\n",
    "    duration_seconds=DURATION_SECONDS_LONG\n",
    ")\n",
    "\n",
    "print(f\"\\nStarted {len(invocation_arns_2)} video generation jobs:\")\n",
    "for i, arn in enumerate(invocation_arns_2, 1):\n",
    "    print(f\"{i}. {arn}\")\n",
    "\n",
    "print(\"\\nüöÄ Jobs are now running asynchronously on Nova Reel infrastructure.\")\n",
    "print(\"   Each ARN is a unique identifier we'll use to track progress.\")\n",
    "print(\"   Videos will be saved to your S3 bucket when complete.\")\n",
    "\n",
    "invocation_arns = invocation_arns + invocation_arns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G. Step 3 - Monitor Job Status\n",
    "\n",
    "This is where we wait for the magic to happen. The `invocation_status_check` function provides intelligent monitoring of our video generation jobs:\n",
    "\n",
    "**Key Operations:**\n",
    "1. **Status tracking** - Maintains state for each job (InProgress/Completed/Failed)\n",
    "2. **Polling loop** - Checks job status every 2 seconds\n",
    "3. **Progress reporting** - Shows count of active jobs, detailed info for long-running jobs\n",
    "4. **Error handling** - Captures and reports failure messages\n",
    "5. **Result collection** - Extracts S3 URIs when videos complete\n",
    "\n",
    "**Smart monitoring:** The function balances responsiveness (2s polling) with API courtesy, providing more detailed updates for jobs that take longer than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invocation_status_check(\n",
    "        bedrock_runtime,\n",
    "        invocation_arns\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Check the status of invocation(s).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    bedrock_runtime: boto3.client\n",
    "        The Bedrock Runtime client.\n",
    "\n",
    "    invocation_arn: list\n",
    "        The invocation ARN(s).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str or list\n",
    "        The S3 URI(s) of the generated video(s). If generation failed,\n",
    "        return None for that video.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle both single ARN and list of ARNs\n",
    "    arns = invocation_arns\n",
    "    \n",
    "    # Track status for each ARN\n",
    "    arn_status = {arn: \"InProgress\" for arn in arns}\n",
    "    results = {}\n",
    "    update_count = 0\n",
    "    arn_in_progress_flag = {arn: False for arn in arns}\n",
    "    \n",
    "    while any(status not in [\"Completed\", \"Failed\"] for status in arn_status.values()):\n",
    "        time.sleep(0.5)\n",
    "        update_count += 1\n",
    "        \n",
    "        for arn in arns:\n",
    "            if arn_status[arn] in [\"Completed\", \"Failed\"]:\n",
    "                continue\n",
    "            try:    \n",
    "                invocation = bedrock_runtime.get_async_invoke(invocationArn=arn)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            status = invocation[\"status\"]\n",
    "            arn_status[arn] = status\n",
    "            \n",
    "            if status == \"InProgress\":\n",
    "                if update_count > 25000 and update_count % 5 == 0:\n",
    "                    start_time = invocation[\"submitTime\"]\n",
    "                    if not arn_in_progress_flag[arn]:\n",
    "                        print(f\"Job {arn} is still in progress. Started at: {start_time}\")\n",
    "                        arn_in_progress_flag[arn] = True\n",
    "                elif update_count % 5 == 0:\n",
    "                    print(f\"Jobs in progress: {sum(1 for s in arn_status.values() if s == 'InProgress')}   \" + \".\" * (update_count%30//5) + \" \" * (5- update_count%30//5), end = \"\\r\")\n",
    "                    \n",
    "            elif status == \"Failed\":\n",
    "                failure_message = invocation[\"failureMessage\"]\n",
    "                print(f\"Job {arn} failed. Failure message: {failure_message}\")\n",
    "                results[arn] = None\n",
    "            \n",
    "            elif status == \"Completed\":\n",
    "                bucket_uri = invocation[\"outputDataConfig\"][\"s3OutputDataConfig\"][\"s3Uri\"]\n",
    "                video_uri = bucket_uri + \"/output.mp4\"\n",
    "                results[arn] = video_uri\n",
    "    \n",
    "    # Return results in same order as input\n",
    "    result_list = [results.get(arn) for arn in arns]\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring video generation progress...\n",
      "Jobs in progress: 2   ...  \r"
     ]
    }
   ],
   "source": [
    "# Monitor job status and get results\n",
    "print(\"Monitoring video generation progress...\")\n",
    "\n",
    "video_uris = invocation_status_check(\n",
    "    bedrock_runtime=bedrock_runtime,\n",
    "    invocation_arns=invocation_arns\n",
    ")\n",
    "\n",
    "print(f\"\\nVideo generation completed!\")\n",
    "print(f\"Generated {len([uri for uri in video_uris if uri])} successful videos:\")\n",
    "for i, uri in enumerate(video_uris, 1):\n",
    "    if uri:\n",
    "        print(f\"{i}. {uri}\")\n",
    "    else:\n",
    "        print(f\"{i}. Failed to generate\")\n",
    "\n",
    "print(\"‚úÖ Success! Your videos are ready in S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Download and Display Videos\n",
    "\n",
    "Now let's download our generated videos from S3 and display them in the notebook:\n",
    "\n",
    "**Key Operations:**\n",
    "1. **Download from S3** - Pull videos from S3 to local storage\n",
    "2. **Display in notebook** - Show videos inline using HTML5 video player\n",
    "3. **Handle multiple videos** - Process all successful generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def download_videos(s3_uris, s3_bucket):\n",
    "    s3_client = session.client('s3')\n",
    "    os.makedirs('generated_videos', exist_ok=True)\n",
    "    downloaded_videos = []\n",
    "    \n",
    "    for i, uri in enumerate(s3_uris):\n",
    "        if uri is None:\n",
    "            continue\n",
    "        s3_key = uri.replace(f\"s3://{s3_bucket}/\", \"\")\n",
    "        local_filename = f\"generated_videos/video_{i+1}.mp4\"\n",
    "        \n",
    "        try:\n",
    "            s3_client.download_file(s3_bucket, s3_key, local_filename)\n",
    "            downloaded_videos.append(local_filename)\n",
    "            print(f\"‚úÖ Downloaded: {local_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to download video {i+1}: {e}\")\n",
    "    \n",
    "    return downloaded_videos\n",
    "\n",
    "def display_video_in_notebook(video_path, width=640):\n",
    "    video_html = f\"\"\"\n",
    "    <video width=\"{width}\" controls>\n",
    "        <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "        Your browser does not support the video tag.\n",
    "    </video>\n",
    "    \"\"\"\n",
    "    return HTML(video_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and display the generated videos\n",
    "if 'video_uris' in locals() and any(video_uris):\n",
    "    print(\"üì• Downloading videos from S3...\")\n",
    "    local_videos = download_videos(video_uris, S3_BUCKET)\n",
    "    \n",
    "    print(f\"\\nüé¨ Displaying {len(local_videos)} generated videos:\")\n",
    "    \n",
    "    for i, video_path in enumerate(local_videos):\n",
    "        display(display_video_in_notebook(video_path))\n",
    "        \n",
    "        file_size = os.path.getsize(video_path) / (1024*1024)\n",
    "        print(f\"üìÅ File: {video_path} ({file_size:.1f} MB)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No videos available. Run the previous sections first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H. Complete Pipeline\n",
    "\n",
    "The `video_generation_pipeline` function demonstrates how all three steps work together seamlessly. This wrapper function:\n",
    "\n",
    "**Key Operations:**\n",
    "1. **Duration normalization** - Adjusts video length to valid Nova Reel values (6s or multiples of 6)\n",
    "2. **Sequential execution** - Calls generate_prompts ‚Üí start_invocation_t2v ‚Üí invocation_status_check\n",
    "3. **Move videos and prompts to centralized location** - All the generated videos and their corresponding prompts will be moved to s3://<your_bucket>/generated_videos/\n",
    "\n",
    "**Output Structure**:\n",
    "\n",
    "The final result will be saved to s3 bucket with the following structures\n",
    "\n",
    "```\n",
    "s3://<your bucket>/\n",
    "‚îî‚îÄ‚îÄ generated_videos/\n",
    "    ‚îú‚îÄ‚îÄ <generated video file>.mp4          # The generated video\n",
    "    ‚îî‚îÄ‚îÄ <generated video file>_prompt.txt   # The prompt used for this video\n",
    "```\n",
    "\n",
    "\n",
    "- <font color='red'>Feel free to change the `user_request` in the cell below</font>\n",
    "- <font color='red'>Change `auto_prompt_generation` if you would like to use your input as video generation prompt directly</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request=\"I would like to generate a video that contains a Experimental Sciences Center: Physics, chemistry and biology laboratories with cutting-edge equipment, educational greenhouse and astronomical observatory.\"\n",
    "auto_prompt_generation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running complete video generation pipeline...\n",
      "num_scenes: 2\n",
      "inovke LLM - attempt 0\n",
      "\n",
      "Generated 1 prompts:\n",
      "1. Aerial shot showcasing the Experimental Sciences Center with sleek modern architecture. Camera pans down to reveal physics labs filled with lasers and oscilloscopes, transitioning to chemistry labs with rows of colorful beakers. Finally, the camera tilts up to an astronomical observatory dome under a star-studded night sky. Render in 4k, ultra-realistic textures, cinematic lighting.\n",
      "\n",
      "\n",
      "inovke Nova Reel - attempt 0\n",
      "Moved video: s3://demo-real-nova/78u7yz6p0kym/output.mp4 -> s3://demo-real-nova/generated_videos/78u7yz6p0kym.mp4\n",
      "Saved prompt: s3://demo-real-nova/generated_videos/78u7yz6p0kym_prompt.txt\n",
      "\n",
      "Pipeline completed! Generated videos:\n",
      "1. s3://demo-real-nova/generated_videos/78u7yz6p0kym.mp4\n",
      "num_scenes: 5\n",
      "inovke LLM - attempt 0\n",
      "\n",
      "Generated 1 prompts:\n",
      "1. Aerial shot of the Experimental Sciences Center at sunrise, showcasing interconnected buildings. Dolly in to the physics lab where lasers cut through mist-filled chambers. Pan right to the chemistry laboratory with rows of colorful beakers and advanced spectrometers. Tilt up to the biology lab featuring high-powered microscopes and DNA sequencers. Track left to the educational greenhouse filled with exotic plants and automated irrigation systems. Camera zooms out to reveal the astronomical observatory with a large telescope pointed at the night sky. Render in 4k, ultra-realistic textures, cinematic lighting, smooth transitions between shots.\n",
      "\n",
      "\n",
      "inovke Nova Reel - attempt 0\n",
      "Moved video: s3://demo-real-nova/wcfbqq19vsmd/output.mp4 -> s3://demo-real-nova/generated_videos/wcfbqq19vsmd.mp4\n",
      "Saved prompt: s3://demo-real-nova/generated_videos/wcfbqq19vsmd_prompt.txt\n",
      "\n",
      "Pipeline completed! Generated videos:\n",
      "1. s3://demo-real-nova/generated_videos/wcfbqq19vsmd.mp4\n"
     ]
    }
   ],
   "source": [
    "from utils.video_generation import video_generation_pipeline\n",
    "\n",
    "\n",
    "print(\"Running complete video generation pipeline...\")\n",
    "# generate one video with 6 seconds duration\n",
    "pipeline_video_uris = video_generation_pipeline(\n",
    "    boto3_session=session,\n",
    "    s3_bucket=S3_BUCKET,\n",
    "    user_request=user_request,\n",
    "    prompt_optimization_flag = auto_prompt_generation,\n",
    "    num_videos=1,\n",
    "    duration_seconds=12,\n",
    ")\n",
    "\n",
    "print(f\"\\nPipeline completed! Generated videos:\")\n",
    "for i, uri in enumerate(pipeline_video_uris, 1):\n",
    "    if uri:\n",
    "        print(f\"{i}. {uri}\")\n",
    "    else:\n",
    "        print(f\"{i}. Failed to generate\")\n",
    "\n",
    "# generate one video with 30 seconds duration\n",
    "pipeline_video_uris = video_generation_pipeline(\n",
    "    boto3_session=session,\n",
    "    s3_bucket=S3_BUCKET,\n",
    "    user_request=user_request,\n",
    "    prompt_optimization_flag = auto_prompt_generation,\n",
    "    num_videos=1,\n",
    "    duration_seconds=30,\n",
    ")\n",
    "\n",
    "print(f\"\\nPipeline completed! Generated videos:\")\n",
    "for i, uri in enumerate(pipeline_video_uris, 1):\n",
    "    if uri:\n",
    "        print(f\"{i}. {uri}\")\n",
    "    else:\n",
    "        print(f\"{i}. Failed to generate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now seen how to generate videos using Nove Reel. Now you can move to the next module to see how to process the videos before evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
